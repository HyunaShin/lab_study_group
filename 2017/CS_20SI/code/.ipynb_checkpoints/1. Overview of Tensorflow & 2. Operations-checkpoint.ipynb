{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1. Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Library\n",
    "#### Theano, Torch, Tensorflow가 가장 많이 사용되는 lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Software     | Creator                                            |Opensource  | Interface   |\n",
    "|------------------|----------------------------------------------------|------------|-------------|\n",
    "|Apache SINGA   | Apache Incubator         |Yes  | Python, C++, Java   |\n",
    "|Caffe   | Berkeley Vision and Learning Center         |Yes  | Python, MATLAB   |\n",
    "|Deeplearning4j   | Skymind engineering team; Deeplearning4j community; originally Adam Gibson\t         |Yes  | Java, Scala, Clojure, Python (Keras)   |\n",
    "|Dlib   | Davis King         |Yes  | C++   |\n",
    "|Keras   | François Chollet         |Yes  | Python   |\n",
    "|Microsoft Cognitive Toolkit   | Microsoft Research         |Yes  | Python, C++, Command line, BrainScript (.NET on roadmap)   |\n",
    "|MXNet  | Distributed (Deep) Machine Learning Community         |Yes  | C++, Python, Julia, Matlab, JavaScript, Go, R, Scala, Perl   |\n",
    "|Neural Designer   | Artelnics         |No  | Graphical user interface   |\n",
    "|OpenNN   | Artelnics         |Yes  | C++   |\n",
    "|TensorFlow   | Google Brain team         |Yes  | Python (Keras), C/C++, Java, Go, R   |\n",
    "|Theano   | Université de Montréal         |Yes  | Python   |\n",
    "|Torch   | Ronan Collobert, Koray Kavukcuoglu, Clement Farabet         |Yes  | Lua, LuaJIT, C, utility library for C++/OpenCL   |\n",
    "|Wolfram Mathematica   | Wolfram Research         |Yes  | Command line, Java, C++   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with one-liner Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TF Learn(tf.contrib.learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test ready\n"
     ]
    }
   ],
   "source": [
    "X_FEATURE = 'x'  # Name of the input feature.\n",
    "\n",
    "# Load dataset.\n",
    "iris = datasets.load_iris() # 총 150개의 붓꽃 사진과 class load\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "print('train and test ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.2,  4.1,  1.5,  0.1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpz3r7cya6\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'save_summary_steps': 100, 'save_checkpoints_secs': 600, '_environment': 'local', '_master': '', 'keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000277F365BAC8>, '_task_id': 0, '_num_ps_replicas': 0, 'save_checkpoints_steps': None, 'tf_random_seed': None, '_evaluation_master': '', '_is_chief': True, 'keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Miniconda3\\envs\\coursera\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Miniconda3\\envs\\coursera\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Miniconda3\\envs\\coursera\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 2.15585, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\USER\\AppData\\Local\\Temp\\tmpz3r7cya6\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.583922, step = 101\n",
      "INFO:tensorflow:global_step/sec: 315.403\n",
      "INFO:tensorflow:Saving checkpoints for 200 into C:\\Users\\USER\\AppData\\Local\\Temp\\tmpz3r7cya6\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 0.536878.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Miniconda3\\envs\\coursera\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Miniconda3\\envs\\coursera\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Miniconda3\\envs\\coursera\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Loading model from checkpoint: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpz3r7cya6\\model.ckpt-200-?????-of-00001.\n"
     ]
    }
   ],
   "source": [
    "# Train.\n",
    "classifier.fit(x_train, y_train, steps=200)\n",
    "predictions = list(classifier.predict(x_test, as_iterable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.633333\n"
     ]
    }
   ],
   "source": [
    "# Score with sklearn.\n",
    "score = metrics.accuracy_score(y_test, predictions)\n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-slim(tf.contrib.slim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contrib 중 하나의 library로, 상위 수준의 개념(argument scoping, layer, variable)으로 모델을 짧고 쉽게 정의할 수 있게 만듦\n",
    "- 많이 사용되는 regularizer를 사용하여 모델을 단순하게 함. VGG, AlexNet과 같이 많이 쓰이는 모델을 개발 해놓음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without TF-Slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = ...\n",
    "with tf.name_scope('conv1_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                           stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(input, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                       trainable=True, name='biases')\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(bias, name=scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with TF-Slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = ...\n",
    "net = slim.conv2d(input, 128, [3, 3], scope='conv1_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Flow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.add(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.add(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the value of a?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(3, 5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.mul(x, y)\n",
    "useless = tf.mul(x, op1)\n",
    "op3 = tf.pow(op2, op1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    op3 = sess.run(op3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.mul(x, y)\n",
    "useless = tf.mul(x, op1)\n",
    "op3 = tf.pow(op2, op1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    op3, not_useless = sess.run([op3, useless])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('gpu:2'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
    "    c = tf.matmul([a,b]) \n",
    "    \n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# Runs the op.\n",
    "print sess.run(c) \n",
    "\n",
    "#Don’t worry about this yet. More on this in week 8!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Graph() - create a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "# to add operators to a graph, set it as default:\n",
    "with g.as_default():\n",
    "    x = tf.add(3, 5)\n",
    "\n",
    "sess = tf.Session(graph=g)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = 3\n",
    "    b = 5\n",
    "    x = tf.add(a, b)\n",
    "    \n",
    "sess = tf.Session(graph=g) # session is run on the graph g\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To handle the default graph:\n",
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not mix default graph and user created graphs\n",
    "g = tf.Graph()\n",
    "a = tf.constant(3)\n",
    "\n",
    "with g.as_default():\n",
    "    b = tf.constant(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why graphs\n",
    "  - Save computation (only run subgraphs that lead to the values you want to fetch)\n",
    "  - Break computation into small, differential pieces to facilitates auto-differentiation\n",
    "  - Facilitate distributed computation, spread the work across multiple CPUs, GPUs, or devices\n",
    "  - Many common machine learning models are commonly taught and visualized as directed graphs already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Tensorflow Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fun with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "x = tf.add(a, b)\n",
    "with tf.Session() as sess:\n",
    "    print sess.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서보드를 활성화 하기위해 그래프의 학습루프가 실행되지 전 라인에 이 코드를 넣어줌\n",
    "  - writer = tf.summary.FileWriter(logs_dir, sess.graph) = 에러남  \n",
    "  - tf.train.FileWriter = 에러남\n",
    "  - tf.train.SummaryWriter = 성공\n",
    "  - 이벤트의 로그가 '.graph'폴더에 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "x = tf.add(a, b)\n",
    "with tf.Session() as sess:\n",
    "    #이 코드가 텐서보드!!\n",
    "    writer = tf.train.SummaryWriter('./graphs', sess.graph)\n",
    "    print sess.run(x)\n",
    "\n",
    "    # close the writer when you’re done using it\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 터미널에서 텐서보드 실행해줘야함\n",
    "  - Next, go to Terminal, run the program. \n",
    "  - Make sure that your present working directory is the same as where you ran your Python code.\n",
    "\n",
    "  - python [yourprogram.py]\n",
    "  - tensorboard --logdir=\"./graphs\"\n",
    "  - 그리고 일루 감 http://localhost:6006/ \n",
    "  - 텐서보드 페이지는 나오는데 아무것도 안뜸!!! 뭐가 잘못된 것인가!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constant types\n",
    "  - 상수유형 공식문서 https://www.tensorflow.org/api_docs/python/constant_op/\n",
    "  - constant 함수로 상수, 스칼라, 텐서값등을 생성할 수 있음\n",
    "### tf.constant(value, dtype=None, shape=None, name='const', verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constant of 1d tensor (vector)\n",
    "a = tf.constant([2, 2], name=\"vector\")\n",
    "\n",
    "# constant of 2x2 tensor (matrix)\n",
    "b = tf.constant([[0, 1], [2, 3]], name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 텐서의 원소로 특정한 값을 생성할수 있음\n",
    "  - 유사함수: numpy.zeros, numpy.zeros_like, numpy.ones, numpy.ones_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.zero(shape, dtype=tf.float32, name=None)\n",
    "  - 모든 원소가 0인 텐서쉐입을 만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.zeros([2, 3], tf.int32) # [[0, 0, 0], [0, 0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.zeros_like(input, dtype=None, name=None, opitmize=True)\n",
    "  - 모든 원소를 0으로 만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_tensor = [[0, 1], [2, 3], [4, 5]]\n",
    "\n",
    "tf.zeros_like(input_tensor)  # [[0, 0], [0, 0], [0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.one(shape, dtype=tf.float32, name=None)\n",
    "  - 모든 원소가 1인 텐서쉐입을 만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.ones([2, 3], tf.int32) # [[1, 1, 1], [1, 1, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.ones_like(input_tensor, dtype=None, name=None, optimize=True)\n",
    "  - 모든 원소를 1로 만드는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_tensor = [[0, 1], [2, 3], [4, 5]]\n",
    "\n",
    "tf.ones_like(input_tensor) # [[1, 1], [1, 1], [1, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.fill(dims, value, name=None)\n",
    "  - 텐서를 한가지 스칼라값으로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.ones([2, 3], 8) # [[8, 8, 8], [8, 8, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.linspace(start, stop, num, name=None)\n",
    "  - 특정 구간에서 균등하게 증가(개수만큼)하는 수열 생성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.linspace(10.0, 13.0, 4, name=\"linspace\") # [10.0 11.0 12.0 13.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.range(start, limit=None, delta=1, dtype=None, name='range')\n",
    "  - 등차수열 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.range(3, 18, 3) # [3, 6, 9, 12, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서는 반복문에 사용할 수 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(4): # OK\n",
    "for _ in tf.range(4): # TypeError(\"'Tensor' object is not iterable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특정 분포에서 난수를 생성할 수 있음\n",
    "  - tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "\n",
    "  - tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None,name=None)\n",
    "\n",
    "  - tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None,name=None)\n",
    "\n",
    "  - tf.random_shuffle(value, seed=None, name=None)\n",
    "\n",
    "  - tf.random_crop(value, size, seed=None, name=None)\n",
    "\n",
    "  - tf.multinomial(logits, num_samples, seed=None, name=None)\n",
    "\n",
    "  - tf.random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Math Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([3, 6])\n",
    "b = tf.constant([2, 2])\n",
    "\n",
    "tf.add(a, b) # >> [5 8]\n",
    "\n",
    "tf.add_n([a, b, b]) # >> [7 10]. Equivalent to a + b + b\n",
    "\n",
    "tf.mul(a, b) # >> [6 12] because mul is element wise\n",
    "\n",
    "f.matmul(a, b) # 복수텐서의 곱셈은 안됌 에러남\n",
    "\n",
    "tf.matmul(tf.reshape(a, shape=[1, 2]), \n",
    "          tf.reshape(b, shape=[2, 1])) # 이렇게 곱할수 있음\n",
    "\n",
    "tf.div(a, b) # >> [1 3]\n",
    "\n",
    "tf.mod(a, b) # >> [1 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Types\n",
    "  ### Python Native Types : 불리안, 숫자, 스트링\n",
    "  - 단일 값은 0차원 텐서 (스칼라)\n",
    "  - 값의 리스트는 1차원 텐서 (벡터)\n",
    "  - 리스트의 리스트는 2차원 텐서 (매트릭스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0차원 상수텐서 - 스칼라\n",
    "t_0 = 19 # Treated as a 0-d tensor, or \"scalar\"\n",
    "tf.zeros_like(t_0) # ==> 0\n",
    "tf.ones_like(t_0) # ==> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1차원 텐서 - 벡터\n",
    "t_1 = [b\"apple\", b\"peach\", b\"grape\"] # treated as a 1-d tensor, or \"vector\"\n",
    "tf.zeros_like(t_1) # ==> ['' '' '']\n",
    "tf.ones_like(t_1) # ==> TypeError: Expected string, got 1 of type 'int' instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2차원 텐서 - 메트릭스\n",
    "t_2 = [[True, False, False],\n",
    "       [False, False, True],\n",
    "       [False, True, False]] # treated as a 2-d tensor, or \"matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Native Types\n",
    "  - 텐서플로우는 Numpy 처럼 tf.int32, tf.float32 독자적인 데이터 타입을 사용함\n",
    "  - https://www.tensorflow.org/versions/r0.11/resources/dims_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Variables\n",
    "  - 상수는 상수임(항상 같음)\n",
    "  - 변수는 할당될수 있고 변경 될수 있음\n",
    "  - 상수는 그래프에 값이 저장되어 있어 그래프를 로딩할때 함께 로딩됨\n",
    "  - 변수는 그래프와 별도로 저장됨(파라미터 서버에 살고 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_const = tf.constant([1.0, 2.0], name=\"my_const\")\n",
    "print tf.get_default_graph().as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare variables\n",
    " ### 변수 생성 및 초기화\n",
    " - tf.Variable 함수로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#create variable a with scalar value\n",
    "a = tf.Variable(2, name=\"scalar\")\n",
    "\n",
    "#create variable b as a vector\n",
    "b = tf.Variable([2, 3], name=\"vector\")\n",
    "\n",
    "#create variable c as a 2x2 matrix\n",
    "c = tf.Variable([[0, 1], [2, 3]], name=\"matrix\")\n",
    "\n",
    "# create variable W as 784 x 10 tensor, filled with zeros\n",
    "W = tf.Variable(tf.zeros([784,10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 변수를 사용하기 전에는 항상 변수를 초기화해야함\n",
    "  - tf.initialize_all_variables() 함수는 모든 변수를 초기화해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initializer = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 일부 변수만 초기화\n",
    "  - initialized_value()함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([784,10], stddev=0.35), name = \"weight\")\n",
    "w2 = tf.Variable(w.initialized_value(), name='w2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수의 평가\n",
    "  - 그냥 프린트하면 텐서와 유형, 쉐입만 볼수 있음\n",
    "  - eval()함수를 사용하면 값까지 볼수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([700, 10]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print W.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수에 값을 할당\n",
    "  -  tf.Variable.assign()함수를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(10)\n",
    "W.assign(100)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print W.eval() # >> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(10)\n",
    "assign_op = W.assign(100)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(assign_op)\n",
    "    print W.eval() # >> 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a variable whose original value is 2\n",
    "a = tf.Variable(2, name=\"scalar\")\n",
    "\n",
    "# assign a * 2 to a and call that op a_times_two\n",
    "a_times_two = a.assign(a * 2)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)# have to initialize a, because a_times_two op depends on the value of a\n",
    "    sess.run(a_times_two) # >> 4\n",
    "    print a_times_two.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 다른 변수를 사용해서 변수를 만들수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([700, 10]))\n",
    "U = tf.Variable(W * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. InteractiveSession\n",
    "  - 인터렉티브 세션은 그것 자체로 디폴트세션으로 작동함\n",
    "  - 따로 run()을 선언하지 않아도 실행됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b\n",
    "\n",
    "# We can just use 'c.eval()' without passing 'sess'\n",
    "print(c.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Control Dependencies\n",
    "  - 두개 이상의 오퍼레이션을 만들었는데, 이 오퍼레이션이 순차적으로 실행 되어야하는경우  tf.Graph.control_dependencies(control_inputs) 함수사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your graph g have 5 ops: a, b, c, d, e\n",
    "with g.control_dependencies([a, b, c]):\n",
    "    d = ....\n",
    "    e = ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Placeholders and feed_dict\n",
    "  - 텐서플로우 프로그램은 다음 두개 단계가 있다.\n",
    "  - Phase 1: assemble a graph\n",
    "  - Phase 2: use a session to execute operations in the graph.\n",
    "  - 우리는 값을 알지 못하는 상태에서 그래프 먼저 그려야한다!\n",
    "  - 그래프를 그리고 나중에 데이터를 공급해주기 위해 placeholder사용함\n",
    " ### tf.placeholder(dtype, shape=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder of type float 32-bit, shape is a vector of 3 elements\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "\n",
    "# create a constant of type float 32-bit, shape is a vector of 3 elements\n",
    "b = tf.constant([5, 5, 5], tf.float32)\n",
    "\n",
    "# use the placeholder as you would a constant or a variable\n",
    "c = a + b # Short for tf.add(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # feed [1, 2, 3] to placeholder a via the dict {a: [1, 2, 3]}\n",
    "    # fetch value of c\n",
    "    print(sess.run(c, {a: [1, 2, 3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Operations, Tensors, etc (using the default graph)\n",
    "a = tf.add(2, 5)\n",
    "b = tf.mul(a, 3)\n",
    "\n",
    "# start up a `Session` using the default graph\n",
    "sess = tf.Session()\n",
    "\n",
    "# define a dictionary that says to replace the value of `a` with 15\n",
    "replace_dict = {a: 15}\n",
    "\n",
    "# Run the session, passing in `replace_dict` as the value to `feed_dict`\n",
    "sess.run(b, feed_dict=replace_dict) # returns 45"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:coursera]",
   "language": "python",
   "name": "conda-env-coursera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
