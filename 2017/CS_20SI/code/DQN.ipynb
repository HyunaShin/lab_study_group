{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import deque\n",
    "import dqn\n",
    "from gym.envs.registration import register\n",
    "import gym\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-02 17:16:28,968] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 5000\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "\n",
    "dis = 0.9\n",
    "REPLAY_MEMORY = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replay_train(mainDQN, targetDQN, train_batch):\n",
    "    x_stack = np.empty(0).reshape(0, input_size)\n",
    "    y_stack = np.empty(0).reshape(0, output_size)\n",
    "    for state, action, reward, next_state, done in train_batch:\n",
    "        Q = mainDQN.predict(state)\n",
    "\n",
    "        if done:\n",
    "            Q[0, action] = reward\n",
    "        else:\n",
    "            Q[0, action] = reward + dis * np.max(targetDQN.predict(next_state))\n",
    "\n",
    "        y_stack = np.vstack([y_stack, Q])\n",
    "        x_stack = np.vstack([x_stack, state])\n",
    "\n",
    "    return mainDQN.update(x_stack, y_stack)\n",
    "\n",
    "def get_copy_var_ops(*, dest_scope_name=\"target\", src_scope_name=\"main\"):\n",
    "\n",
    "    op_holder = []\n",
    "\n",
    "    src_vars = tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "\n",
    "    for src_var, dest_var in zip(src_vars, dest_vars):\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "\n",
    "    return op_holder\n",
    "\n",
    "\n",
    "def bot_play(mainDQN, env=env):\n",
    "    state = env.reset()\n",
    "    reward_sum = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action = np.argmax(mainDQN.predict(state))\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        if done:\n",
    "            print(\"Total score: {}\".format(reward_sum))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0  steps: 13\n",
      "Episode: 1  steps: 24\n",
      "Loss:  1.78031\n",
      "Episode: 2  steps: 12\n",
      "Episode: 3  steps: 11\n",
      "Episode: 4  steps: 14\n",
      "Episode: 5  steps: 12\n",
      "Episode: 6  steps: 13\n",
      "Episode: 7  steps: 12\n",
      "Episode: 8  steps: 10\n",
      "Episode: 9  steps: 11\n",
      "Episode: 10  steps: 10\n",
      "Episode: 11  steps: 9\n",
      "Loss:  5.40925\n",
      "Episode: 12  steps: 9\n",
      "Episode: 13  steps: 10\n",
      "Episode: 14  steps: 10\n",
      "Episode: 15  steps: 16\n",
      "Episode: 16  steps: 11\n",
      "Episode: 17  steps: 10\n",
      "Episode: 18  steps: 14\n",
      "Episode: 19  steps: 12\n",
      "Episode: 20  steps: 10\n",
      "Episode: 21  steps: 8\n",
      "Loss:  1312.22\n",
      "Episode: 22  steps: 10\n",
      "Episode: 23  steps: 12\n",
      "Episode: 24  steps: 8\n",
      "Episode: 25  steps: 9\n",
      "Episode: 26  steps: 9\n",
      "Episode: 27  steps: 8\n",
      "Episode: 28  steps: 9\n",
      "Episode: 29  steps: 11\n",
      "Episode: 30  steps: 8\n",
      "Episode: 31  steps: 10\n",
      "Loss:  365.26\n",
      "Episode: 32  steps: 11\n",
      "Episode: 33  steps: 10\n",
      "Episode: 34  steps: 11\n",
      "Episode: 35  steps: 10\n",
      "Episode: 36  steps: 10\n",
      "Episode: 37  steps: 10\n",
      "Episode: 38  steps: 9\n",
      "Episode: 39  steps: 15\n",
      "Episode: 40  steps: 9\n",
      "Episode: 41  steps: 10\n",
      "Loss:  298.223\n",
      "Episode: 42  steps: 10\n",
      "Episode: 43  steps: 10\n",
      "Episode: 44  steps: 11\n",
      "Episode: 45  steps: 12\n",
      "Episode: 46  steps: 10\n",
      "Episode: 47  steps: 9\n",
      "Episode: 48  steps: 10\n",
      "Episode: 49  steps: 12\n",
      "Episode: 50  steps: 10\n",
      "Episode: 51  steps: 11\n",
      "Loss:  291.975\n",
      "Episode: 52  steps: 54\n",
      "Episode: 53  steps: 57\n",
      "Episode: 54  steps: 45\n",
      "Episode: 55  steps: 32\n",
      "Episode: 56  steps: 58\n",
      "Episode: 57  steps: 140\n",
      "Episode: 58  steps: 32\n",
      "Episode: 59  steps: 43\n",
      "Episode: 60  steps: 34\n",
      "Episode: 61  steps: 63\n",
      "Loss:  5.34222\n",
      "Episode: 62  steps: 77\n",
      "Episode: 63  steps: 50\n",
      "Episode: 64  steps: 48\n",
      "Episode: 65  steps: 37\n",
      "Episode: 66  steps: 38\n",
      "Episode: 67  steps: 51\n",
      "Episode: 68  steps: 44\n",
      "Episode: 69  steps: 71\n",
      "Episode: 70  steps: 34\n",
      "Episode: 71  steps: 47\n",
      "Loss:  10.212\n",
      "Episode: 72  steps: 42\n",
      "Episode: 73  steps: 123\n",
      "Episode: 74  steps: 60\n",
      "Episode: 75  steps: 96\n",
      "Episode: 76  steps: 163\n",
      "Episode: 77  steps: 160\n",
      "Episode: 78  steps: 67\n",
      "Episode: 79  steps: 106\n",
      "Episode: 80  steps: 143\n",
      "Episode: 81  steps: 47\n",
      "Loss:  417.753\n",
      "Episode: 82  steps: 136\n",
      "Episode: 83  steps: 33\n",
      "Episode: 84  steps: 51\n",
      "Episode: 85  steps: 147\n",
      "Episode: 86  steps: 117\n",
      "Episode: 87  steps: 63\n",
      "Episode: 88  steps: 48\n",
      "Episode: 89  steps: 89\n",
      "Episode: 90  steps: 57\n",
      "Episode: 91  steps: 103\n",
      "Loss:  5.03202\n",
      "Episode: 92  steps: 83\n",
      "Episode: 93  steps: 169\n",
      "Episode: 94  steps: 70\n",
      "Episode: 95  steps: 153\n",
      "Episode: 96  steps: 191\n",
      "Episode: 97  steps: 131\n",
      "Episode: 98  steps: 86\n",
      "Episode: 99  steps: 122\n",
      "Episode: 100  steps: 82\n",
      "Episode: 101  steps: 739\n",
      "Loss:  4.35775\n",
      "Episode: 102  steps: 47\n",
      "Episode: 103  steps: 150\n",
      "Episode: 104  steps: 77\n",
      "Episode: 105  steps: 58\n",
      "Episode: 106  steps: 77\n",
      "Episode: 107  steps: 131\n",
      "Episode: 108  steps: 125\n",
      "Episode: 109  steps: 99\n",
      "Episode: 110  steps: 45\n",
      "Episode: 111  steps: 141\n",
      "Loss:  182.489\n",
      "Episode: 112  steps: 60\n",
      "Episode: 113  steps: 58\n",
      "Episode: 114  steps: 215\n",
      "Episode: 115  steps: 39\n",
      "Episode: 116  steps: 126\n",
      "Episode: 117  steps: 241\n",
      "Episode: 118  steps: 110\n",
      "Episode: 119  steps: 39\n",
      "Episode: 120  steps: 174\n",
      "Episode: 121  steps: 50\n",
      "Loss:  0.787672\n",
      "Episode: 122  steps: 285\n",
      "Episode: 123  steps: 209\n",
      "Episode: 124  steps: 235\n",
      "Episode: 125  steps: 164\n",
      "Episode: 126  steps: 77\n",
      "Episode: 127  steps: 83\n",
      "Episode: 128  steps: 57\n",
      "Episode: 129  steps: 96\n",
      "Episode: 130  steps: 83\n",
      "Episode: 131  steps: 121\n",
      "Loss:  0.488281\n",
      "Episode: 132  steps: 111\n",
      "Episode: 133  steps: 204\n",
      "Episode: 134  steps: 65\n",
      "Episode: 135  steps: 69\n",
      "Episode: 136  steps: 175\n",
      "Episode: 137  steps: 111\n",
      "Episode: 138  steps: 112\n",
      "Episode: 139  steps: 325\n",
      "Episode: 140  steps: 77\n",
      "Episode: 141  steps: 254\n",
      "Loss:  0.708153\n",
      "Episode: 142  steps: 199\n",
      "Episode: 143  steps: 72\n",
      "Episode: 144  steps: 74\n",
      "Episode: 145  steps: 167\n",
      "Episode: 146  steps: 237\n",
      "Episode: 147  steps: 197\n",
      "Episode: 148  steps: 219\n",
      "Episode: 149  steps: 100\n",
      "Episode: 150  steps: 143\n",
      "Episode: 151  steps: 102\n",
      "Loss:  1.33653\n",
      "Episode: 152  steps: 125\n",
      "Episode: 153  steps: 62\n",
      "Episode: 154  steps: 48\n",
      "Episode: 155  steps: 245\n",
      "Episode: 156  steps: 230\n",
      "Episode: 157  steps: 57\n",
      "Episode: 158  steps: 213\n",
      "Episode: 159  steps: 71\n",
      "Episode: 160  steps: 131\n",
      "Episode: 161  steps: 58\n",
      "Loss:  0.658904\n",
      "Episode: 162  steps: 64\n",
      "Episode: 163  steps: 64\n",
      "Episode: 164  steps: 53\n",
      "Episode: 165  steps: 97\n",
      "Episode: 166  steps: 65\n",
      "Episode: 167  steps: 115\n",
      "Episode: 168  steps: 380\n",
      "Episode: 169  steps: 61\n",
      "Episode: 170  steps: 135\n",
      "Episode: 171  steps: 252\n",
      "Loss:  116.689\n",
      "Episode: 172  steps: 126\n",
      "Episode: 173  steps: 99\n",
      "Episode: 174  steps: 116\n",
      "Episode: 175  steps: 168\n",
      "Episode: 176  steps: 125\n",
      "Episode: 177  steps: 50\n",
      "Episode: 178  steps: 69\n",
      "Episode: 179  steps: 419\n",
      "Episode: 180  steps: 67\n",
      "Episode: 181  steps: 78\n",
      "Loss:  0.695187\n",
      "Episode: 182  steps: 66\n",
      "Episode: 183  steps: 191\n",
      "Episode: 184  steps: 69\n",
      "Episode: 185  steps: 63\n",
      "Episode: 186  steps: 60\n",
      "Episode: 187  steps: 52\n",
      "Episode: 188  steps: 97\n",
      "Episode: 189  steps: 162\n",
      "Episode: 190  steps: 125\n",
      "Episode: 191  steps: 167\n",
      "Loss:  2.36047\n",
      "Episode: 192  steps: 130\n",
      "Episode: 193  steps: 82\n",
      "Episode: 194  steps: 66\n",
      "Episode: 195  steps: 124\n",
      "Episode: 196  steps: 69\n",
      "Episode: 197  steps: 91\n",
      "Episode: 198  steps: 112\n",
      "Episode: 199  steps: 211\n",
      "Episode: 200  steps: 81\n",
      "Episode: 201  steps: 45\n",
      "Loss:  1.83495\n",
      "Episode: 202  steps: 55\n",
      "Episode: 203  steps: 40\n",
      "Episode: 204  steps: 171\n",
      "Episode: 205  steps: 211\n",
      "Episode: 206  steps: 134\n",
      "Episode: 207  steps: 154\n",
      "Episode: 208  steps: 70\n",
      "Episode: 209  steps: 83\n",
      "Episode: 210  steps: 52\n",
      "Episode: 211  steps: 63\n",
      "Loss:  1.34356\n",
      "Episode: 212  steps: 107\n",
      "Episode: 213  steps: 75\n",
      "Episode: 214  steps: 49\n",
      "Episode: 215  steps: 67\n",
      "Episode: 216  steps: 49\n",
      "Episode: 217  steps: 59\n",
      "Episode: 218  steps: 83\n",
      "Episode: 219  steps: 63\n",
      "Episode: 220  steps: 125\n",
      "Episode: 221  steps: 67\n",
      "Loss:  1.16707\n",
      "Episode: 222  steps: 71\n",
      "Episode: 223  steps: 66\n",
      "Episode: 224  steps: 128\n",
      "Episode: 225  steps: 62\n",
      "Episode: 226  steps: 198\n",
      "Episode: 227  steps: 71\n",
      "Episode: 228  steps: 94\n",
      "Episode: 229  steps: 173\n",
      "Episode: 230  steps: 289\n",
      "Episode: 231  steps: 56\n",
      "Loss:  1.06043\n",
      "Episode: 232  steps: 176\n",
      "Episode: 233  steps: 199\n",
      "Episode: 234  steps: 109\n",
      "Episode: 235  steps: 100\n",
      "Episode: 236  steps: 69\n",
      "Episode: 237  steps: 44\n",
      "Episode: 238  steps: 266\n",
      "Episode: 239  steps: 55\n",
      "Episode: 240  steps: 80\n",
      "Episode: 241  steps: 209\n",
      "Loss:  1.28873\n",
      "Episode: 242  steps: 69\n",
      "Episode: 243  steps: 75\n",
      "Episode: 244  steps: 317\n",
      "Episode: 245  steps: 72\n",
      "Episode: 246  steps: 118\n",
      "Episode: 247  steps: 49\n",
      "Episode: 248  steps: 184\n",
      "Episode: 249  steps: 225\n",
      "Episode: 250  steps: 53\n",
      "Episode: 251  steps: 69\n",
      "Loss:  1.4058\n",
      "Episode: 252  steps: 86\n",
      "Episode: 253  steps: 76\n",
      "Episode: 254  steps: 99\n",
      "Episode: 255  steps: 50\n",
      "Episode: 256  steps: 65\n",
      "Episode: 257  steps: 62\n",
      "Episode: 258  steps: 111\n",
      "Episode: 259  steps: 304\n",
      "Episode: 260  steps: 55\n",
      "Episode: 261  steps: 191\n",
      "Loss:  2.78974\n",
      "Episode: 262  steps: 62\n",
      "Episode: 263  steps: 139\n",
      "Episode: 264  steps: 70\n",
      "Episode: 265  steps: 64\n",
      "Episode: 266  steps: 163\n",
      "Episode: 267  steps: 61\n",
      "Episode: 268  steps: 51\n",
      "Episode: 269  steps: 83\n",
      "Episode: 270  steps: 64\n",
      "Episode: 271  steps: 63\n",
      "Loss:  0.971678\n",
      "Episode: 272  steps: 51\n",
      "Episode: 273  steps: 169\n",
      "Episode: 274  steps: 144\n",
      "Episode: 275  steps: 258\n",
      "Episode: 276  steps: 78\n",
      "Episode: 277  steps: 60\n",
      "Episode: 278  steps: 203\n",
      "Episode: 279  steps: 197\n",
      "Episode: 280  steps: 205\n",
      "Episode: 281  steps: 210\n",
      "Loss:  2.11429\n",
      "Episode: 282  steps: 340\n",
      "Episode: 283  steps: 216\n",
      "Episode: 284  steps: 80\n",
      "Episode: 285  steps: 47\n",
      "Episode: 286  steps: 61\n",
      "Episode: 287  steps: 119\n",
      "Episode: 288  steps: 78\n",
      "Episode: 289  steps: 74\n",
      "Episode: 290  steps: 61\n",
      "Episode: 291  steps: 162\n",
      "Loss:  1.76493\n",
      "Episode: 292  steps: 62\n",
      "Episode: 293  steps: 71\n",
      "Episode: 294  steps: 76\n",
      "Episode: 295  steps: 75\n",
      "Episode: 296  steps: 232\n",
      "Episode: 297  steps: 97\n",
      "Episode: 298  steps: 391\n",
      "Episode: 299  steps: 152\n",
      "Episode: 300  steps: 56\n",
      "Episode: 301  steps: 132\n",
      "Loss:  2.47204\n",
      "Episode: 302  steps: 202\n",
      "Episode: 303  steps: 206\n",
      "Episode: 304  steps: 56\n",
      "Episode: 305  steps: 142\n",
      "Episode: 306  steps: 186\n",
      "Episode: 307  steps: 56\n",
      "Episode: 308  steps: 52\n",
      "Episode: 309  steps: 68\n",
      "Episode: 310  steps: 61\n",
      "Episode: 311  steps: 139\n",
      "Loss:  3.92604\n",
      "Episode: 312  steps: 63\n",
      "Episode: 313  steps: 46\n",
      "Episode: 314  steps: 58\n",
      "Episode: 315  steps: 95\n",
      "Episode: 316  steps: 74\n",
      "Episode: 317  steps: 458\n",
      "Episode: 318  steps: 74\n",
      "Episode: 319  steps: 174\n",
      "Episode: 320  steps: 64\n",
      "Episode: 321  steps: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.8199\n",
      "Episode: 322  steps: 166\n",
      "Episode: 323  steps: 72\n",
      "Episode: 324  steps: 56\n",
      "Episode: 325  steps: 375\n",
      "Episode: 326  steps: 150\n",
      "Episode: 327  steps: 59\n",
      "Episode: 328  steps: 83\n",
      "Episode: 329  steps: 94\n",
      "Episode: 330  steps: 103\n",
      "Episode: 331  steps: 60\n",
      "Loss:  2.47375\n",
      "Episode: 332  steps: 58\n",
      "Episode: 333  steps: 63\n",
      "Episode: 334  steps: 68\n",
      "Episode: 335  steps: 227\n",
      "Episode: 336  steps: 215\n",
      "Episode: 337  steps: 68\n",
      "Episode: 338  steps: 172\n",
      "Episode: 339  steps: 81\n",
      "Episode: 340  steps: 77\n",
      "Episode: 341  steps: 72\n",
      "Loss:  1.1932\n",
      "Episode: 342  steps: 87\n",
      "Episode: 343  steps: 188\n",
      "Episode: 344  steps: 342\n",
      "Episode: 345  steps: 191\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    max_episodes = 5000\n",
    "    replay_buffer = deque()\n",
    "\n",
    "    last_100_game_reward = deque()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        mainDQN = dqn.DQN(sess, input_size, output_size, name=\"main\")\n",
    "        targetDQN = dqn.DQN(sess, input_size, output_size, name=\"target\")\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        copy_ops = get_copy_var_ops(dest_scope_name=\"target\",\n",
    "                                    src_scope_name=\"main\")\n",
    "        sess.run(copy_ops)\n",
    "\n",
    "        for episode in range(max_episodes):\n",
    "            e = 1. / ((episode / 10) + 1)\n",
    "            done = False\n",
    "            step_count = 0\n",
    "            state = env.reset()\n",
    "\n",
    "            while not done:\n",
    "                if np.random.rand(1) < e:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action = np.argmax(mainDQN.predict(state))\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                if done:  \n",
    "                    reward = -100\n",
    "\n",
    "                replay_buffer.append((state, action, reward, next_state, done))\n",
    "                if len(replay_buffer) > REPLAY_MEMORY:\n",
    "                    replay_buffer.popleft()\n",
    "\n",
    "                state = next_state\n",
    "                step_count += 1\n",
    "\n",
    "            print(\"Episode: {}  steps: {}\".format(episode, step_count))\n",
    "\n",
    "            if episode % 10 == 1: \n",
    "                for _ in range(50):\n",
    "                    minibatch = random.sample(replay_buffer, 10)\n",
    "                    loss, _ = replay_train(mainDQN, targetDQN, minibatch)\n",
    "\n",
    "                print(\"Loss: \", loss)\n",
    "                sess.run(copy_ops)\n",
    "\n",
    "            last_100_game_reward.append(step_count)\n",
    "\n",
    "            if len(last_100_game_reward) > 100:\n",
    "                last_100_game_reward.popleft()\n",
    "\n",
    "                avg_reward = np.mean(last_100_game_reward)\n",
    "\n",
    "                if avg_reward > 4950:\n",
    "                    print(\"Game Cleared in \",episode, \"episodes with avg reward \",avg_reward)\n",
    "                    break\n",
    "                    \n",
    "        env2 = wrappers.Monitor(env, 'gym-results', force=True)\n",
    "\n",
    "        for i in range(200):\n",
    "            bot_play(mainDQN, env=env2)\n",
    "\n",
    "        env2.close()\n",
    "        gym.upload(\"gym-results\", api_key=\"sk_VT2wPcSSOylnlPORltmQ\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
